{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from dataset import DialogDataset\n",
    "import transformers\n",
    "import torch\n",
    "from models import SegmentationModel\n",
    "from utils import check_token_stats, test_prediction, extract_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = 'multi_woz_v22'\n",
    "MODEL_TYPE = 'gpt2'\n",
    "TASK_TYPE = 'classification'\n",
    "LR = 1e-05\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "label_name = 'label_cls' if TASK_TYPE == 'classification' else 'label_reg'\n",
    "PATH = f'saved/{DATA_NAME}_{MODEL_TYPE}_{TASK_TYPE}_{LR}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/home/dongi/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c55a651b96a434c85dbe64a36ae2543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens num -- min: 30, max: 786, mean: 202.56462585034015, std: 86.53795045423138\n"
     ]
    }
   ],
   "source": [
    "check_token_stats(datasets.load_dataset(path=DATA_NAME), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/home/dongi/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.load_dataset(path=DATA_NAME, split='test')\n",
    "test_dataset =  DialogDataset(test_data, tokenizer)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegmentationModel(model_name='gpt2', model_type=MODEL_TYPE, task_type=TASK_TYPE).to(device)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.6694649971542401, precision: 0.6998363825673063, f1-score: 0.6843138680823213\n"
     ]
    }
   ],
   "source": [
    "test_logit, test_pred, test_real, test_recall, test_precision, test_f1 = test_prediction(model, test_loader, label_name, device)\n",
    "#print(f\"recall: {test_recall}, precision: {test_precision}, f1-score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicted Sample] ...\n",
      "i  need  train  reservations  from  nor wich  to  cam bridge \n",
      "        %Prob% : 0.5412\n",
      "        %Logit% : 0.1651839166879654\n",
      " i  have  133  trains  matching  your  request  is  there  a  specific  day  and  time  you  would  like  to  travel \n",
      "        %Prob% : 0.7399\n",
      "        %Logit% : 1.0456702709197998\n",
      " id  like  to  leave  on  m onday  and  arrive  by  1800 \n",
      "        %Prob% : 0.7006\n",
      "        %Logit% : 0.8503118753433228\n",
      " there  are  12  trains  for  the  day  and  time  you  request  would  you  like  to  book  it \n",
      "        %Prob% : 0.5714\n",
      "        %Logit% : 0.2875508964061737\n",
      " now \n",
      "        %Prob% : 0.8752\n",
      "        %Logit% : 1.9477922916412354\n",
      " before  booking  i  would  also  like  to  know  the  travel  time  price  and  departure  time \n",
      "        %Prob% : 0.5631\n",
      "        %Logit% : 0.2536555826663971\n",
      " please \n",
      "        %Prob% : 0.8865\n",
      "        %Logit% : 2.055598258972168\n",
      " there  are  12  trains  meeting  your  needs  with  the  first  leaving  at  05 16  and  the  last  one  leaving  at  16 16  do  you  want  to  book  one  of  these \n",
      "        %Prob% : 0.7843\n",
      "        %Logit% : 1.2911295890808105\n",
      " no  hold  off  on  booking  for  now  can  you  help  me  find  an  attraction  called  c in eworld  cinema \n",
      "        %Prob% : 0.7126\n",
      "        %Logit% : 0.9078818559646606\n",
      " yes  it  is  a  cinema  located  in  the  south  part  of  town  what  information  would  you  like  on  it \n",
      "        %Prob% : 0.8705\n",
      "        %Logit% : 1.9053007364273071\n",
      " yes  that  was  all  i  needed  thank  you \n",
      "        %Prob% : 0.6045\n",
      "        %Logit% : 0.4243539571762085\n",
      " very  much \n",
      "        %Prob% : 0.6544\n",
      "        %Logit% : 0.63841313123703\n",
      " thank  you  for  using  our  system <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongi/segmentation/utils.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  for each_sample_id, each_sample_logit in zip(torch.tensor(sample['input_ids']), torch.tensor(sample_logits.squeeze())):\n"
     ]
    }
   ],
   "source": [
    "NUM = 0\n",
    "extract_sample(NUM, test_logit, test_dataset, tokenizer, TASK_TYPE='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Truth Sample] ...\n",
      "I need train reservations from norwich to cambridge\n",
      "\n",
      "I have 133 trains matching your request. Is there a specific day and time you would like to travel?\n",
      "\n",
      "I'd like to leave on Monday and arrive by 18:00.\n",
      "\n",
      "There are 12 trains for the day and time you request. Would you like to book it now?\n",
      "\n",
      "Before booking, I would also like to know the travel time, price, and departure time please.\n",
      "\n",
      "There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these?\n",
      "\n",
      "No hold off on booking for now. Can you help me find an attraction called cineworld cinema?\n",
      "\n",
      "Yes it is a cinema located in the south part of town what information would you like on it?\n",
      "\n",
      "Yes, that was all I needed. Thank you very much!\n",
      "\n",
      "Thank you for using our system.\n"
     ]
    }
   ],
   "source": [
    "print(\"[Truth Sample] ...\")\n",
    "if test_dataset.data.info.builder_name == 'multi_woz_v22':\n",
    "    print(*test_data[NUM]['turns']['utterance'], sep='\\n\\n')\n",
    "elif test_dataset.data.info.builder_name == 'daily_dialog':\n",
    "    print(*test_data[NUM]['dialog'], sep='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "esm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
