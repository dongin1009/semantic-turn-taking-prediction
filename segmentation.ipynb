{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: multi_woz_v22/v2.2_active_only\n",
      "Found cached dataset multi_woz_v22 (/data/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/6719c8b21478299411a0c6fdb7137c3ebab2e6425129af831687fb7851c69eb5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ee2c3d7ad4fd3aa64e2e5fa4b42ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset(path='multi_woz_v22', cache_dir='/data/.cache/huggingface/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.6.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.0.attn.masked_bias', 'h.11.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'classifier.weight', 'h.10.attn.masked_bias', 'h.1.attn.masked_bias', 'classifier.bias', 'h.7.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2', cache_dir='/data/.cache/huggingface/transformers', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = transformers.AutoModelForTokenClassification.from_pretrained('gpt2', cache_dir='/data/.cache/huggingface/transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\tdef __init__(self, patience=7, verbose=True, delta=0, path='./checkpoint.pt'):\n",
    "\t\tself.patience = patience\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.counter = 0\n",
    "\t\tself.best_score = None\n",
    "\t\tself.early_stop = False\n",
    "\t\tself.val_loss_min = float(\"inf\")\n",
    "\t\tself.delta = delta\n",
    "\t\tself.path = path\n",
    "\n",
    "\tdef __call__(self, val_loss, model):\n",
    "\t\tif self.patience > 0:\n",
    "\t\t\tscore = -val_loss\n",
    "\n",
    "\t\t\tif self.best_score is None:\n",
    "\t\t\t\tself.best_score = score\n",
    "\t\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\t\telif score < self.best_score + self.delta:\n",
    "\t\t\t\tself.counter += 1\n",
    "\t\t\t\tprint(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "\t\t\t\tif self.counter >= self.patience:\n",
    "\t\t\t\t\tself.early_stop = True\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.best_score = score\n",
    "\t\t\t\tself.save_checkpoint(val_loss, model)\n",
    "\t\t\t\tself.counter = 0\n",
    "\n",
    "\tdef save_checkpoint(self, val_loss, model):\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint(\"\")\n",
    "\t\t\tprint(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "\t\ttorch.save(model.state_dict(), self.path)\n",
    "\t\tself.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer = tokenizer, max_length=None):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = self.tokenizer.model_max_length if max_length is None else max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        output = {}\n",
    "        each_utt = self.data[index]['turns']['utterance']\n",
    "        label = tokenizer(each_utt)['attention_mask']\n",
    "        for i in range(len(label)):\n",
    "            label[i][-1] = 0\n",
    "        token_label = torch.tensor(sum(label, []), dtype=torch.long)[:self.max_length]\n",
    "        token_label = (~token_label.bool()).float()\n",
    "        if len(token_label) < self.max_length: # assign padding token label\n",
    "            token_label = torch.cat([token_label[:self.max_length], torch.zeros(self.max_length - len(token_label))])\n",
    "        token_dict = tokenizer(' '.join(each_utt), truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors='pt')\n",
    "        output['input_ids'], output['attention_mask'] = token_dict['input_ids'], token_dict['attention_mask']\n",
    "        output['labels'] = token_label.type(torch.LongTensor)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DialogDataset(data['train'], tokenizer)\n",
    "valid_dataset = DialogDataset(data['validation'], tokenizer)\n",
    "test_dataset = DialogDataset(data['test'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True, path=f'saved/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcaeb123fad43449ddff7e95cfd529e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa5d90c0ff741e6bc61f8e3921d4c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.1031, Valid Loss: 0.0872\n",
      "\n",
      "Validation loss decreased (inf --> 5.490523).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edae389b837411f83fae19619b00e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e072dfb98adc45caba4bddd03d3ef402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.1875, Valid Loss: 0.0853\n",
      "\n",
      "Validation loss decreased (5.490523 --> 5.371929).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069ab8b7e0434173bbe02120d676313c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de70762efbf46acb2c94df0e30b4c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.2630, Valid Loss: 0.0810\n",
      "\n",
      "Validation loss decreased (5.371929 --> 5.101747).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3a0c3a03df4c3ebe47dda6b0026e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ec436da534f93a0c19883623e8fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.3303, Valid Loss: 0.0846\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4d9c925cc4402b2c5f153a2ff5df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b426730d1e124818adccead3bf9588fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.3888, Valid Loss: 0.0864\n",
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8e0b8827a942a2956e4b756e345e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5df73c3a9db41eb9d4668bdaedf6002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.4392, Valid Loss: 0.0949\n",
      "EarlyStopping counter: 3 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7583dfb82da401191bb93b078034eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ce071dede543bd98bb8bdfbf9de55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.4831, Valid Loss: 0.1028\n",
      "EarlyStopping counter: 4 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e09695262ff4e19b292d9d1455e3b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd4a73062114f54b7c827fbf88038a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.5220, Valid Loss: 0.0988\n",
      "EarlyStopping counter: 5 out of 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b25a624a444853aa0c6beaf2c2d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dongi/segmentation/segmentation.ipynb 셀 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244534c61625f54696e79227d/home/dongi/segmentation/segmentation.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m out \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39mattention_mask, labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244534c61625f54696e79227d/home/dongi/segmentation/segmentation.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mloss\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244534c61625f54696e79227d/home/dongi/segmentation/segmentation.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244534c61625f54696e79227d/home/dongi/segmentation/segmentation.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244534c61625f54696e79227d/home/dongi/segmentation/segmentation.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = 0.0\n",
    "for each_epoch in range(1, epochs):\n",
    "    model.train()\n",
    "    for each_batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = each_batch['input_ids'].to(device)\n",
    "        attention_mask = each_batch['attention_mask'].to(device)\n",
    "        labels = each_batch['labels'].to(device)\n",
    "        out = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        for each_batch in tqdm(valid_loader):\n",
    "            input_ids = each_batch['input_ids'].to(device)\n",
    "            attention_mask = each_batch['attention_mask'].to(device)\n",
    "            labels = each_batch['labels'].to(device)\n",
    "            out = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            valid_loss += out.loss.item()\n",
    "        print(f'Epoch {each_epoch}: Train Loss: {train_loss / len(train_loader):.4f}, Valid Loss: {valid_loss / len(valid_loader):.4f}')\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at {epoch-early_stopping_patience} !\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "\tmodel.eval()\n",
    "\tpred = []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor each_batch in tqdm(test_loader):\n",
    "\t\t\tinput_ids = each_batch['input_ids'].to(device)\n",
    "\t\t\tattention_mask = each_batch['attention_mask'].to(device)\n",
    "\t\t\tout = model(input_ids, attention_mask=attention_mask)\n",
    "\t\t\tpred.append(out.logits.cpu().numpy())\n",
    "\treturn pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(pred):\n",
    "\tprediction = []\n",
    "\tfor each_pred in pred:\n",
    "\t\tprediction.append(each_pred[0])\n",
    "\treturn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d15d107c0144c51bc5be7476ce561bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1024, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.sigmoid(torch.tensor(test_pred[0].squeeze())[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.8800, 0.8568, 0.8547,  ..., 0.0011, 0.0010, 0.0010]),\n",
       "indices=tensor([ 30, 159,  64,  ..., 160, 659,  20]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v, ind = prob.sort(descending=True)\n",
    "prob.sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8800, 0.8568, 0.8547, 0.8234, 0.7969, 0.7779, 0.7765, 0.6645, 0.5243,\n",
       "         0.3890]),\n",
       " tensor([ 30, 159,  64,  84,  44, 139, 118, 172, 144, 138]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:10], ind[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9],\n",
       "        [ 30],\n",
       "        [ 44],\n",
       "        [ 64],\n",
       "        [ 84],\n",
       "        [118],\n",
       "        [139],\n",
       "        [159],\n",
       "        [172],\n",
       "        [179]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_dataset[0]['labels']==1).int().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor(179)\n",
      "The first sample data has 0.8 accuracy\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for each_label in (test_dataset[0]['labels']==1).int().nonzero().squeeze():\n",
    "    if each_label in ind[:10]:\n",
    "       acc+=1\n",
    "    else:\n",
    "        print(each_label)\n",
    "print(f'The first sample data has {acc/10} accuracy') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9458,   30,   13,   30,   13,   30,   30,   30,    0,   13])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['input_ids'].squeeze()[(test_dataset[0]['labels']==1).int().nonzero().squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bridge?.?.???!.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[0]['input_ids'].squeeze()[(test_dataset[0]['labels']==1).int().nonzero().squeeze()]) # real turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'???..??! cinema cinema'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[0]['input_ids'].squeeze()[ind[:10]]) # predict turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기호 전처리 필요,,,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.5570, -5.4620, -4.2655,  ..., -5.7574, -5.7514, -4.8050]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(test_pred[0])[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_pred(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   40,   761,  4512,  ..., 50256, 50256, 50256]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0, 0,  ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].sum(), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/v3.0.2/_modules/transformers/modeling_bert.html#BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoModelForTokenClassification: \n",
    "1. sequence_output = AutoModel 의 output(각 토큰의 vector)\n",
    "2. sequence_output = dropout(config.hidden_dropout_prob)\n",
    "3. logits = Linear(token_dim -> num_labels)\n",
    "4. loss = CrossEntropy 인데, attention_mask가 1인 토큰만 계산. logits, labels 모두"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "esm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
